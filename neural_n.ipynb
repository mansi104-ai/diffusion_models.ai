{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation , PillowWriter\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from diffusion_utilities import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING THINGS UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextUnet(nn.Module):\n",
    "    def __init__(self, in_channels, n_feat= 256, n_cfeat=10, height=28):\n",
    "        super(ContextUnet, self).__init__()\n",
    "\n",
    "        #number of input channels , number of intermediate features and number of classes \n",
    "        self.in_channels = in_channels\n",
    "        self.n_feat = n_feat\n",
    "        self.n_cfeat = n_cfeat\n",
    "        self.h = height# assume h == w, must be divisible by 4, so also by 28,24,20,16.....\n",
    "\n",
    "        #initialize the initial convolutional layer \n",
    "        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res = True)\n",
    "\n",
    "        #initialize the down sampling path of the u-net with two levels\n",
    "        self.down1 = UnetDown(n_feat, n_feat) #down1 #[10,256,8,8]\n",
    "        self.down2 = UnetDown(n_feat, 2*n_feat)  #down2 #[10,256,4,4]\n",
    "        \n",
    "\n",
    "        #original :self_to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())\n",
    "        self.to_vec = nn.Seuqntial(nn.AvgPool2d(7), nn.GELU())\n",
    "\n",
    "        #Embed the timestep and context label with a one-layer fully connected neural network\n",
    "        self.timeembed1 = Embed(1, 2*n_feat)\n",
    "        self.timeembed2 = Embed(1, 1*n_feat)\n",
    "        self.contextembed1 = Embed(n_cfeat, 2*n_feat)\n",
    "        self.contextembed2 = Embed(n_cfeat, 1*n_feat)\n",
    "\n",
    "        #initialize the final convulational layers to the map to the same number of channels as the input image\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2*n_feat, n_feat, 3,1,1), # reduce the number of feature maps, #in_channels, #out channels, stride =1 , padding= 0\n",
    "            nn.GroupNorm(8, n_feat), #Normalize\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_feat, self.in_channels,3,1,1),#map to same number of channels as input\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
